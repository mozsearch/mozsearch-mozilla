#!/usr/bin/env bash

set -x # Show commands
set -eu # Errors/undefined vars are fatal
set -o pipefail # Check all commands in a pipeline

date

echo Downloading Gecko
pushd $INDEX_ROOT
if [ -d "gecko-dev" ]
then
    echo "Found pre-existing gecko-dev folder; skipping re-download."
else
    wget -nv https://s3-us-west-2.amazonaws.com/searchfox.repositories/gecko-dev.tar
    tar xf gecko-dev.tar
    rm gecko-dev.tar
fi
popd

date

echo Downloading Gecko blame
pushd $INDEX_ROOT
if [ -d "gecko-blame" ]
then
    echo "Found existing gecko-blame folder; skipping re-download."
else
    wget -nv https://s3-us-west-2.amazonaws.com/searchfox.repositories/gecko-blame.tar
    tar xf gecko-blame.tar
    rm gecko-blame.tar
fi
popd

date

echo Downloading git to hg map
pushd $INDEX_ROOT
# We only need "recent" mapfile entries and attempting to download the full mapfile
# results in a 503 error so we just get the map entries from some fixed recent date.
wget -O git_hg.map -nv https://mapper.mozilla-releng.net/gecko-dev/mapfile/since/2018-08-01
popd

date

echo Updating git
pushd $GIT_ROOT
# The repo may have been uploaded while checked out to some non-master
# revision (to match the hg revision used in taskcluster)
git checkout master
git pull
popd

date

function move_file {
    mkdir -p "$(dirname $2)"
    mv "$1" "$2"
}

# Edit this to e.g. try.revision.ee64db93dcc149da9313460317257b8c42eec5b2 or whatever
# to test other revisions. If you do this, also override INDEXED_GIT_REV below to some sane
# git-equivalent of the revision because most likely it won't find anything in the mapfile.
# This defaults to the most recent searchfox indexing run for mozilla-central.
REVISION=mozilla-central.latest

pushd $INDEX_ROOT
curl -SsfL --compressed https://index.taskcluster.net/v1/task/gecko.v2.$REVISION.firefox.linux64-searchfox-debug/artifacts/public/build/target.json > target.json
INDEXED_HG_REV=$(python $MOZSEARCH_PATH/scripts/read-json.py target.json moz_source_stamp)
INDEXED_GIT_REV=$(awk -v REV=$INDEXED_HG_REV '$2 ~ REV { print $1 }' git_hg.map)

# If INDEXED_GIT_REV gets set, that means the gecko-dev repo includes the code for which
# the taskcluster indexing job ran. So we can download the result of that indexing
# job and use it. Otherwise, it means gecko-dev is lagging behind the canonical hg
# repo, and we don't have the source corresponding to the indexing run on taskcluster.
# In that case we should just build the latest version of gecko-dev that we do have,
# so that we have analysis data for a version of the source we have.
# Whether or not we do the build is decided in the "build" script in the same folder
# as this file, which detects this scenario by the absence of the
# linux64.mozsearch-index.zip file.

if [ -n "$INDEXED_GIT_REV" ]; then
    pushd $GIT_ROOT
    # Since we're using a prebuilt index at a particular rev, sync our local repo to the same rev
    git checkout $INDEXED_GIT_REV
    popd

    rm -rf analysis && mkdir -p analysis
    rm -rf objdir && mkdir -p objdir
    rm -f analysis-files.list analysis-dirs.list

    # Download the artifacts from taskcluster for each platform that we're indexing
    for PLATFORM in linux64 macosx64 win64; do
        date

        # First check that the latest artifacts for the platform match the revision we want, otherwise emit a warning and skip it
        curl -SsfL --compressed https://index.taskcluster.net/v1/task/gecko.v2.$REVISION.firefox.$PLATFORM-searchfox-debug/artifacts/public/build/target.json > $PLATFORM.json
        PLATFORM_HG_REV=$(python $MOZSEARCH_PATH/scripts/read-json.py $PLATFORM.json moz_source_stamp)
        if [ "$PLATFORM_HG_REV" != "$INDEXED_HG_REV" ]; then
            echo "WARNING: Most recent analysis for $PLATFORM was for hg rev $PLATFORM_HG_REV; expected $INDEXED_HG_REV; skipping analysis merge step for this platform."
            continue;
        fi

        echo "Downloading artifacts for $PLATFORM..."

        # Download the C++ analysis and unpack into a platform-specific folder
        rm -f $PLATFORM.mozsearch-index.zip
        wget -O $PLATFORM.mozsearch-index.zip -nv https://index.taskcluster.net/v1/task/gecko.v2.$REVISION.firefox.$PLATFORM-searchfox-debug/artifacts/public/build/target.mozsearch-index.zip
        mkdir -p analysis-$PLATFORM
        unzip -q $PLATFORM.mozsearch-index.zip -d analysis-$PLATFORM

        # Download the Rust save-analysis files. These all get unpacked into the objdir directly because the files
        # are already in platform-specific subfolders inside the zipfile, so there won't be any collisions. The
        # rust-indexer.rs tool will take care of combining all the analysis files correctly.
        rm -f $PLATFORM.mozsearch-rust.zip
        wget -O $PLATFORM.mozsearch-rust.zip -nv https://index.taskcluster.net/v1/task/gecko.v2.$REVISION.firefox.$PLATFORM-searchfox-debug/artifacts/public/build/target.mozsearch-rust.zip
        unzip -q $PLATFORM.mozsearch-rust.zip -d objdir

        # Download generated sources tarballs and unpack into platform-specific folder
        rm -f $PLATFORM.generated-files.tar.gz
        wget -O $PLATFORM.generated-files.tar.gz -nv https://index.taskcluster.net/v1/task/gecko.v2.$REVISION.firefox.$PLATFORM-searchfox-debug/artifacts/public/build/target.generated-files.tar.gz
        mkdir -p generated-$PLATFORM
        tar -x -z -C generated-$PLATFORM -f $PLATFORM.generated-files.tar.gz

        # Special cases - buildid.h and mozilla-config.h show up in two places in a regular
        # objdir and the analysis tarball will correspondingly also have two instances of
        # the analysis file. The generated-files tarball only has one copy, so we manually
        # make the other copy to make things match up. The best would be if the gecko build
        # system didn't actually produce two copies of these files.
        cp generated-$PLATFORM/buildid.h        generated-$PLATFORM/dist/include/buildid.h
        cp generated-$PLATFORM/mozilla-config.h generated-$PLATFORM/dist/include/mozilla-config.h

        # We get analysis data for generated files, some of which aren't included
        # in the generated-files tarball that we get from taskcluster. Most of these
        # missing files are dummy unified build files that we don't care about, and
        # we can just delete those.
        # If there are other such cases, then we'll get zero-byte files generated by
        # output-file.rs since it won't be able to find the source file corresponding to
        # the analysis file. In those cases we should ensure the generated file is
        # included in the target.generated-files.tar.gz tarball that comes out of the
        # taskcluster indexing job. Bug 1440879 can be used as a guide.
        pushd analysis-$PLATFORM/__GENERATED__
        set +x  # Turn off echoing of commands and output only relevant things to avoid bloating logfiles
        find . -type f -name "Unified*" |
        while read GENERATED_ANALYSIS; do
            if [ ! -f "$INDEX_ROOT/generated-$PLATFORM/$GENERATED_ANALYSIS" ]; then
                echo "Remove unified compilation generated-file $GENERATED_ANALYSIS"
                rm "$GENERATED_ANALYSIS"
            fi
        done
        set -x
        # Also drop any directories that got emptied as a result
        find . -depth -type d -empty -delete
        popd

        # FIXME: Deal better with merging generated files.
        # Different platforms might have different generated sources and so the merged
        # analysis data might refer to line numbers that don't exist. For now we only copy
        # files from the generated-$PLATFORM folder into objdir/ if the file doesn't
        # already exist there. Effectively this means that if the same generated file
        # exists for multiple platforms, but has different contents, we will prefer the
        # one from the platform encountered earliest in this loop.
        # See bug 1487583 comment 3 for some more discussion.
        pushd generated-$PLATFORM
        set +x  # Turn off echoing of commands and output only relevant things to avoid bloating logfiles
        find . -type f |
        while read GENERATED_FILE; do
            if [ ! -f "../objdir/$GENERATED_FILE" ]; then
                # Generated file wasn't encountered for previously processed platforms
                echo "Taking generated file $GENERATED_FILE from $PLATFORM"
                move_file "$GENERATED_FILE" "../objdir/$GENERATED_FILE"
                if [ -f "../analysis-$PLATFORM/__GENERATED__/$GENERATED_FILE" ]; then
                    # Move the analysis file as well
                    move_file "../analysis-$PLATFORM/__GENERATED__/$GENERATED_FILE" "../analysis/__GENERATED__/$GENERATED_FILE"
                fi
            fi
        done
        set -x
        popd

        # Throw away any leftover generated files and their analysis, so that they don't
        # accidentally get merged later. The above loop should have copied any that we
        # care about into the main objdir/ and analysis/ folders.
        rm -rf generated-$PLATFORM
        rm -rf analysis-$PLATFORM/__GENERATED__

        # List all the analysis files we have left. We will merge these across platforms
        # after this per-platform loop is complete.
        pushd analysis-$PLATFORM
        find . -type d >> ../analysis-dirs.list
        find . -type f >> ../analysis-files.list
        popd

    done    # end PLATFORM loop

    date

    # Finally, merge the analysis files for the non-generated source files. All the files
    # are going to be listed in the analysis-files.list, possibly duplicated across
    # platforms, so we deduplicate the filenames and merge each filename across platforms.
    set +x  # Turn off echoing of commands and output only relevant things to avoid bloating logfiles
    sort analysis-dirs.list | uniq |
    while read ANALYSIS_DIR; do
        mkdir -p "analysis/$ANALYSIS_DIR"
    done
    sort analysis-files.list | uniq |
    while read ANALYSIS_FILE; do
        echo "Merging analyses for $ANALYSIS_FILE"
        RUST_LOG=info $MOZSEARCH_PATH/tools/target/release/merge-analyses analysis-*/$ANALYSIS_FILE > analysis/$ANALYSIS_FILE
    done
    set -x

    # Free up disk space, we don't need these per-platform analysis files any more.
    rm -rf analysis-*

else
    echo "WARNING: Unable to find git equivalent for hg rev $INDEXED_HG_REV; falling back to local build..."
fi
popd

date

# Generate the blame information after checking out the GIT_ROOT to appropriate
# revision above, so that the blame repo's head matches the git repo's head.
echo Generating blame information
python $MOZSEARCH_PATH/blame/transform-repo.py $GIT_ROOT $BLAME_ROOT $INDEX_ROOT/git_hg.map

# Point the blame repo's HEAD to the commit matching what we have in in the src repo. Note
# that we use `git reset --soft` because we don't need anything in the repo's working dir.
if [ -n "$INDEXED_GIT_REV" ]; then
    pushd $BLAME_ROOT
    BLAME_REV=$(git log -1 --grep=$INDEXED_GIT_REV --pretty=format:%H)
    if [ -z "$BLAME_REV" ]; then
        echo "Unable to find blame rev for $INDEXED_GIT_REV"
        exit 1;
    fi
    git reset --soft $BLAME_REV
    popd
fi

date
