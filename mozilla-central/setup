#!/bin/bash

set -e # Errors are fatal
set -x # Show commands

date

echo Downloading Gecko
pushd $INDEX_ROOT
if [ -d "gecko-dev" ]
then
    echo "Found pre-existing gecko-dev folder; skipping re-download."
else
    wget -q https://s3-us-west-2.amazonaws.com/searchfox.repositories/gecko-dev.tar
    tar xf gecko-dev.tar
    rm gecko-dev.tar
fi
popd

date

echo Downloading Gecko blame
pushd $INDEX_ROOT
if [ -d "gecko-blame" ]
then
    echo "Found existing gecko-blame folder; skipping re-download."
else
    wget -q https://s3-us-west-2.amazonaws.com/searchfox.repositories/gecko-blame.tar
    tar xf gecko-blame.tar
    rm gecko-blame.tar
fi
popd

date

echo Downloading git to hg map
pushd $INDEX_ROOT
wget -q https://mapper.mozilla-releng.net/gecko-dev/mapfile/full
mv full git_hg.map
popd

date

echo Updating git
pushd $GIT_ROOT
# The repo may have been uploaded while checked out to some non-master
# revision (to match the hg revision used in taskcluster)
git checkout master
git pull
popd

date

function move_file {
    mkdir -p "$(dirname $2)"
    mv "$1" "$2"
}

# Edit this to e.g. try.revision.ee64db93dcc149da9313460317257b8c42eec5b2 or whatever
# to test other revisions. If you do this, also override INDEXED_GIT_REV below to some sane
# git-equivalent of the revision because most likely it won't find anything in the mapfile.
# This defaults to the most recent searchfox indexing run for mozilla-central.
REVISION=mozilla-central.latest

pushd $INDEX_ROOT
wget -nv https://index.taskcluster.net/v1/task/gecko.v2.$REVISION.firefox.linux64-searchfox-debug/artifacts/public/build/target.json
INDEXED_HG_REV=$(python $MOZSEARCH_PATH/scripts/read-json.py target.json moz_source_stamp)
INDEXED_GIT_REV=$(awk -v REV=$INDEXED_HG_REV '$2 ~ REV { print $1 }' git_hg.map)

# If INDEXED_GIT_REV gets set, that means the gecko-dev repo includes the code for which
# the taskcluster indexing job ran. So we can download the result of that indexing
# job and use it. Otherwise, it means gecko-dev is lagging behind the canonical hg
# repo, and we don't have the source corresponding to the indexing run on taskcluster.
# In that case we should just build the latest version of gecko-dev that we do have,
# so that we have analysis data for a version of the source we have.
# Whether or not we do the build is decided in the "build" script in the same folder
# as this file, which detects this scenario by the absence of the
# target.mozsearch-index.zip file.

if [ -n "$INDEXED_GIT_REV" ]; then
    pushd $GIT_ROOT
    # Since we're using a prebuilt index at a particular rev, sync our local repo to the same rev
    git checkout $INDEXED_GIT_REV
    popd

    # Download the C++ analysis, Rust save-analysis files, and generated sources tarballs.

    rm -rf $INDEX_ROOT/analysis
    rm -rf $INDEX_ROOT/objdir

    rm -f target.mozsearch-index.zip
    wget -nv https://index.taskcluster.net/v1/task/gecko.v2.$REVISION.firefox.linux64-searchfox-debug/artifacts/public/build/target.mozsearch-index.zip
    mkdir -p $INDEX_ROOT/analysis
    unzip target.mozsearch-index.zip -d $INDEX_ROOT/analysis

    rm -f target.mozsearch-rust.zip
    wget -nv https://index.taskcluster.net/v1/task/gecko.v2.$REVISION.firefox.linux64-searchfox-debug/artifacts/public/build/target.mozsearch-rust.zip
    mkdir -p $INDEX_ROOT/objdir
    unzip target.mozsearch-rust.zip -d $INDEX_ROOT/objdir

    rm -f target.generated-files.tar.gz
    wget -nv https://index.taskcluster.net/v1/task/gecko.v2.$REVISION.firefox.linux64-searchfox-debug/artifacts/public/build/target.generated-files.tar.gz
    tar -x -z -C $INDEX_ROOT/objdir -f target.generated-files.tar.gz

    # Special cases - buildid.h and mozilla-config.h show up in two places in a regular
    # objdir and the analysis tarball will correspondingly also have two instances of
    # the analysis file. The generated-files tarball only has one copy, so we manually
    # make the other copy to make things match up. The best would be if the gecko build
    # system didn't actually produce two copies of these files.
    cp $INDEX_ROOT/objdir/buildid.h $INDEX_ROOT/objdir/dist/include/buildid.h
    cp $INDEX_ROOT/objdir/mozilla-config.h $INDEX_ROOT/objdir/dist/include/mozilla-config.h

    # Download the macOS tarballs and merge them into the linux tarballs.
    # Check to make sure they are for the same hg revision first.
    wget -O macosx.json -nv https://index.taskcluster.net/v1/task/gecko.v2.$REVISION.firefox.macosx64-searchfox-debug/artifacts/public/build/target.json
    MACOSX_HG_REV=$(python $MOZSEARCH_PATH/scripts/read-json.py macosx.json moz_source_stamp)
    if [ "$INDEXED_HG_REV" == "$MACOSX_HG_REV" ]; then
        rm -f macosx.mozsearch-index.zip
        wget -O macosx.mozsearch-index.zip -nv https://index.taskcluster.net/v1/task/gecko.v2.$REVISION.firefox.macosx64-searchfox-debug/artifacts/public/build/target.mozsearch-index.zip
        mkdir -p $INDEX_ROOT/analysis-macosx
        unzip macosx.mozsearch-index.zip -d $INDEX_ROOT/analysis-macosx

        # Throw the macOS save-analysis files into the objdir too. They'll get
        # passed to rust-indexer.rs along with the linux ones, and rust-indexer.rs
        # will take care of combining the analysis files correctly.
        rm -f macosx.mozsearch-rust.zip
        wget -O macosx.mozsearch-rust.zip -nv https://index.taskcluster.net/v1/task/gecko.v2.$REVISION.firefox.macosx64-searchfox-debug/artifacts/public/build/target.mozsearch-rust.zip
        unzip macosx.mozsearch-rust.zip -d $INDEX_ROOT/objdir

        rm -f macosx.generated-files.tar.gz
        wget -O macosx.generated-files.tar.gz -nv https://index.taskcluster.net/v1/task/gecko.v2.$REVISION.firefox.macosx64-searchfox-debug/artifacts/public/build/target.generated-files.tar.gz
        mkdir -p $INDEX_ROOT/generated-macosx
        tar -x -z -C $INDEX_ROOT/generated-macosx -f macosx.generated-files.tar.gz

        # FIXME: Deal better with merging generated files yet; macOS might have different
        # generated sources than linux and so the analysis data might be for line numbers
        # that don't exist. For now let's just extract any macOS-only generated files
        # and their analysis data, and delete the rest. In effect, for cases where the
        # generated file differs between Linux and macOS, we use the Linux version.
        # See bug 1487583 comment 3.
        pushd generated-macosx
        find . -type f |
        while read GENERATED_FILE; do
            if [ ! -f "../objdir/$GENERATED_FILE" ]; then
                # Generated file exists only for macOS
                move_file "$GENERATED_FILE" "../objdir/$GENERATED_FILE"
                if [ -f "../analysis-macosx/__GENERATED__/$GENERATED_FILE" ]; then
                    # Move the macOS analysis file as well
                    move_file "../analysis-macosx/__GENERATED__/$GENERATED_FILE" "../analysis/__GENERATED__/$GENERATED_FILE"
                fi
            fi
        done
        popd
        rm -rf analysis-macosx/__GENERATED__

        # Merge analysis files for non-generated source files from macOS. This is as simple
        # as unioning the lines in the analysis files.
        pushd analysis-macosx
        find . -type f |
        while read ANALYSIS_FILE; do
            if [ ! -f "../analysis/$ANALYSIS_FILE" ]; then
                move_file "$ANALYSIS_FILE" "../analysis/$ANALYSIS_FILE"
            else
                cat "$ANALYSIS_FILE" "../analysis/$ANALYSIS_FILE" | sort | uniq > ../analysis.merged
                mv "../analysis.merged" "../analysis/$ANALYSIS_FILE"
            fi
        done
        popd
    else
        echo "WARNING: Most recent macOS analysis was for hg rev $MACOSX_HG_REV; expected $INDEXED_HG_REV; skipping macOS analysis merge step."
    fi

    # We get analysis data for generated files, some of which aren't included
    # in the generated-files tarball that we get from taskcluster. Most of these
    # missing files are dummy unified build files that we don't care about, and
    # we can just delete those.
    # If there are other such cases, then we'll get zero-byte files generated by
    # output-file.rs since it won't be able to find the source file corresponding to
    # the analysis file. In those cases we should ensure the generated file is
    # included in the target.generated-files.tar.gz tarball that comes out of the
    # taskcluster indexing job. Bug 1440879 can be used as a guide.
    pushd $INDEX_ROOT/analysis/__GENERATED__
    find . -type f -name "Unified*" |
    while read GENERATED_ANALYSIS; do
        if [ ! -f $INDEX_ROOT/objdir/$GENERATED_ANALYSIS ]; then
            rm "$GENERATED_ANALYSIS"
        fi
    done
    # Also drop any directories that got emptied as a result
    find . -depth -type d -empty -delete
    popd
else
    echo "WARNING: Unable to find git equivalent for hg rev $INDEXED_HG_REV; falling back to local build..."
fi
popd

date

# Generate the blame information after checking out the GIT_ROOT to appropriate
# revision above, so that the blame repo's head matches the git repo's head.
echo Generating blame information
python $MOZSEARCH_PATH/blame/transform-repo.py $GIT_ROOT $BLAME_ROOT $INDEX_ROOT/git_hg.map

# Point the blame repo's HEAD to the commit matching what we have in in the src repo. Note
# that we use `git reset --soft` because we don't need anything in the repo's working dir.
if [ -n "$INDEXED_GIT_REV" ]; then
    pushd $BLAME_ROOT
    BLAME_REV=$(git log -1 --grep=$INDEXED_GIT_REV --pretty=format:%H)
    if [ -z "$BLAME_REV" ]; then
        echo "Unable to find blame rev for $INDEXED_GIT_REV"
        exit 1;
    fi
    git reset --soft $BLAME_REV
    popd
fi

date
